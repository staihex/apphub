/* eslint-disable @typescript-eslint/no-explicit-any */

import markdownit from 'markdown-it';
import { createStyles } from 'antd-style';
import React, { useEffect, useRef } from 'react';
import HeaderMenu from '../components/Header/HeaderMenu';
import { Attachments, AttachmentsProps, Bubble, useXAgent, useXChat } from '@ant-design/x';
import { Affix, Avatar, Button, Col, Form, GetProp, Input, Layout, message, Result, Row, Select, Typography } from 'antd';
import { AudioOutlined, CloudUploadOutlined, PoweroffOutlined, SendOutlined, UserOutlined } from '@ant-design/icons';
import { useFetch } from '../contexts/useFetch';
import { API_KEY } from '../config/config';
import WelcomeCard from '../components/Other/WelcomeCard';
import { getBase64 } from '../utils/utils';
import WaveformPlayer from '../components/Voice/WaveformPlayer';
import OpenAIClientManager from '../utils//OpenAIClientManager';
import application13 from '../../public/images/application13.png'
import Link from 'antd/es/typography/Link';
import '../styles.css'

const { Text } = Typography;

const useStyle = createStyles(({ token, css }) => {
  return {
    chat: css`
      height: 100%;
      width: 100%;
      max-width: 700px;
      margin: 0 auto;
      box-sizing: border-box;
      display: flex;
      flex-direction: column;
      flex: 1;
      padding: 24px 24px 0px 24px;
      gap: 16px;
    `,
    messages: css`
      flex: 1;
    `,
    sender: css`
      box-shadow: ${token.boxShadow};
    `,
  };
});

const SpeechToText: React.FC = () => {
  const { data } = useFetch();
  const { styles } = useStyle();
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const [messageApi, contextHolder] = message.useMessage();

  const [form] = Form.useForm();
  const currentModelrRef = React.useRef('whisper-3');
  const md = markdownit({ html: true, breaks: true });

  const [fileItems, setFileItems] = React.useState<GetProp<AttachmentsProps, 'items'>>([]);
  const [, setBase64Strs] = React.useState([]);
  const base64StrRef = React.useRef([]);
  const fileItemsRef = React.useRef<any>(null);
  const userFileStorageRef = useRef<Map<any, File>>(new Map());

  const currentApiKeyrRef = React.useRef(API_KEY);

  const [, setContent] = React.useState('');
  const isStart = React.useRef(true);
  const [isRecording, setIsRecording] = React.useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);


  const customFetch = async (url: string | URL | Request, options: any) => {
    // æ·»åŠ è‡ªå®šä¹‰çš„è¯·æ±‚å¤´
    const headers = {
      authorization: options.headers.authorization,
      // 'content-type': options.headers['content-type'],
      'content-length': options.headers['content-length'],
    };

    // åˆ›å»ºæ–°çš„è¯·æ±‚é€‰é¡¹å¯¹è±¡
    const newOptions = {
      ...options,
      headers,
    };

    console.log("customFetch", url, newOptions);

    try {
      // ä½¿ç”¨è‡ªå®šä¹‰çš„è¯·æ±‚é€‰é¡¹å‘é€è¯·æ±‚
      const response = await fetch(url, newOptions);
      if (!response.ok) {
        // å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯ 2xxï¼ŒæŠ›å‡ºé”™è¯¯
        const errorData = await response.json();
        if (isStart.current) {
          isStart.current = false;
          messageApi.open({
            type: 'error',
            content: errorData.error.message,
          });
          throw new Error(`HTTP error! status: ${response.status}`);
        }
      }
      return response;
    } catch (error) {
      // å¤„ç†è¯·æ±‚é”™è¯¯
      console.error('Request failed:', error);
      throw error;
    }
  };

  const openAIManager = OpenAIClientManager.getInstance();
  openAIManager.initializeClient(currentApiKeyrRef.current, customFetch);

  const [agent] = useXAgent({
    request: async (_info, callbacks) => {
      const { onSuccess, onUpdate, onError } = callbacks;

      let content: string = '';
      let fullContent = ''; // å­˜å‚¨å®Œæ•´çš„æµæ•°æ®
      let currentIndex = 0; // å½“å‰è¾“å‡ºçš„å­—ç¬¦ç´¢å¼•
      let isTyping = false; // æ˜¯å¦æ­£åœ¨æ‰“å­—
      const typingInterval = 5; // é€å­—è¾“å‡ºçš„é—´éš”æ—¶é—´

      try {
        const stream = await openAIManager.getClient().audio.transcriptions.create({
          model: currentModelrRef.current,
          file: fileItemsRef.current,
        });

        // å®šæ—¶å™¨å‡½æ•°ï¼šé€å­—è¾“å‡º
        const typeNextChar = () => {
          if (currentIndex < fullContent.length) {
            onUpdate(fullContent.slice(0, currentIndex + 1)); // é€å­—æ›´æ–°
            currentIndex++;
            setTimeout(typeNextChar, typingInterval); // ç»§ç»­ä¸‹ä¸€æ¬¡
          } else {
            isTyping = false; // æ‰“å­—ç»“æŸ
          }
        };

        console.log(stream);

        content += stream.text || '';
        fullContent = content; // è¿½åŠ åˆ°å®Œæ•´çš„æµæ•°æ®

        if (!isTyping) {
          isTyping = true;
          typeNextChar();
        }

        // ç¡®ä¿æ‰€æœ‰å­—ç¬¦æœ€ç»ˆè¾“å‡º
        const checkCompletion = setInterval(() => {
          if (!isTyping && currentIndex < fullContent.length) {
            isTyping = true;
            typeNextChar();
          } else if (currentIndex >= fullContent.length) {
            clearInterval(checkCompletion);
            onSuccess(fullContent);
          }
        }, 50);
      } catch (error: any) {
        // handle error
        onError(error);
      }

    },
  });

  const { onRequest, messages } = useXChat({
    agent,
  });

  useEffect(() => {
    // å½“æ•°æ®æ›´æ–°æ—¶ï¼Œæ›´æ–°OpenAIå®¢æˆ·ç«¯
    if (currentApiKeyrRef.current == '') {
      messageApi.open({
        type: 'info',
        content: 'è¯·å…ˆé…ç½®API_KEY',
      });
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  useEffect(() => {
    // å½“æ¶ˆæ¯åˆ—è¡¨æ›´æ–°æ—¶ï¼Œæ»šåŠ¨åˆ°æœ€åº•éƒ¨
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const items: GetProp<typeof Bubble.List, 'items'> = messages.map(({ id, message, status }, index) => ({
    key: id,
    // typing: {step: 1000, interval: 100},
    avatar: { src: status == 'local' ? <Avatar style={{ backgroundColor: '#2467FF' }} icon={<UserOutlined />} /> : <Avatar src={application13} /> },
    role: status === 'local' ? 'local' : 'ai',
    // loading: status === 'loading',
    styles: {
      content: {
        borderRadius: 16,
        display: 'flex',
        justifyContent: 'flex-end',
        backgroundColor: status === 'local' ? 'rgb(239, 246, 255)' : '#FFF',
      },
    },
    messageRender: () => {
      if (status === 'local') {
        return <WaveformPlayer file={userFileStorageRef.current.get(index)} autoPlay={false} />
      } else {
        return <Typography style={{ marginTop: '10px' }}>
          <div dangerouslySetInnerHTML={{ __html: md.render(message) }} />
        </Typography>
      }

    },
  }));

  const roles: GetProp<typeof Bubble.List, 'roles'> = {
    ai: {
      placement: 'start',
      typing: { step: 5, interval: 20 },
      styles: {
        content: {
          borderRadius: 16,
        },
      },
    },
    local: {
      placement: 'end',
      variant: 'shadow',
    },
  };

  const handleFileChange: GetProp<typeof Attachments, 'onChange'> = async (info) => {
    setFileItems(info.fileList.map(file => file));
    fileItemsRef.current = info.file
    userFileStorageRef.current.set(messages.length, fileItemsRef.current);
    const base64StrsArr: any = [];
    for (let i = 0; i < info.fileList.length; i++) {
      const file = info.fileList[i];
      if (file?.originFileObj) {
        const base64 = await getBase64(file.originFileObj);
        console.log(base64)
        // å°†æ¯ä¸ªæ–‡ä»¶çš„ Base64 ç¼–ç æ·»åŠ åˆ°æ•°ç»„ä¸­
        base64StrsArr.push(base64);
      }
    }
    base64StrRef.current = base64StrsArr
    setBase64Strs(base64StrsArr);
  }

  const sharedAttachmentProps: AttachmentsProps = {
    beforeUpload: () => false,
    items: fileItems,
    onChange: handleFileChange,
  };

  type ExtractFunc<T> = T extends (...args: any) => any ? T : never;
  const getPlaceholderFn = (
    inlinePlaceholder: ReturnType<ExtractFunc<AttachmentsProps['placeholder']>>,
  ) => {
    return (type: 'inline' | 'drop') =>
      type === 'drop'
        ? {
          title: 'Drop file here',
        }
        : inlinePlaceholder;
  };
  // å¼€å§‹å½•éŸ³
  const startRecording = () => {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      const constraints = {
        audio: {
          channelCount: 1, // å•å£°é“
          sampleRate: 16000, // é‡‡æ ·ç‡è®¾ç½®ä¸º16000 Hz
          sampleSize: 16, // é‡‡æ ·ä½æ•°ä¸º16bit
          echoCancellation: true, // å›éŸ³æ¶ˆé™¤
          noiseSuppression: true // é™å™ª
        }
      };
      navigator.mediaDevices
        .getUserMedia(constraints)
        .then((stream) => {
          const mediaRecorder = new MediaRecorder(stream);
          mediaRecorderRef.current = mediaRecorder;
          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunksRef.current.push(event.data);
            }
          };
          mediaRecorder.start();
          setIsRecording(true);
        })
        .catch((error) => {
          console.error('å½•éŸ³å¤±è´¥:', error);
          message.error('å½•éŸ³å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
        });
    } else {
      message.error('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
    }
  };

  // åœæ­¢å½•éŸ³å¹¶ä¸Šä¼ 
  const stopRecording = () => {
    const mediaRecorder = mediaRecorderRef.current;
    if (mediaRecorder) {
      mediaRecorder.stop();
      setIsRecording(false);
      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        audioElementRef.current = new Audio(audioUrl);

        // å°†å½•éŸ³æ–‡ä»¶ä¸Šä¼ 
        const file: any = new File([audioBlob], `recorded_${Date.now()}.wav`, { type: 'audio/wav' });
        console.log("file", file)
        file.uid = Date.now();
        // handleUpload(file);
        handleFileChange({ file: file, fileList: [file] });
        onSubmit(' ')
        audioChunksRef.current = []; // æ¸…ç©ºéŸ³é¢‘æ•°æ®
      };
    }
  };

  const onSubmit = (nextContent: string) => {

    form.validateFields().then(() => {
      if (!nextContent) return;
      onRequest(nextContent);
      setContent('');
      setFileItems([]);
      isStart.current = true;
    }).catch((info) => {
      console.log('Validate Failed:', info);
      return;
    });
    
  };

  return (
    <>
      {contextHolder}
      <Layout style={{ minHeight: '100vh', display: 'flex', flexDirection: 'column' }}>
        {/* HeaderMenu */}
        <Affix offsetTop={0}>
          <Layout.Header style={{ background: 'transparent', width: '100%', padding: 0 }}>
            <HeaderMenu name='è¯­éŸ³è¯†åˆ«' />
          </Layout.Header>
        </Affix>

        {/* å†…å®¹åŒºåŸŸ */}
        <Row style={{ flex: 1 }}>
          <Col sm={6} md={4} style={{ backgroundColor: '#FFF', padding: '24px 24px 0px 24px' }}>
            <Affix offsetTop={90}>
              <div>
              <Form layout="vertical" form={form}>
                  <Form.Item initialValue="whisper-3" label="è¯­éŸ³è¯†åˆ«æ¨¡å‹" name='model' rules={[{ required: true, message: 'è¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹' }]}>
                    <Select
                      style={{ width: '100%' }}
                      onChange={(value) => {
                        currentModelrRef.current = value;
                      }}
                      options={data?.audio2text}
                    />
                  </Form.Item>
                  <Form.Item style={{marginBottom:'8px'}} initialValue={API_KEY} label="API_KEY" name='apikey' rules={[{ required: true, message: 'è¯·è¾“å…¥API_KEY' }]}>
                    <Input onChange={(e) => {
                      // æ›´æ–°API_KEY
                      currentApiKeyrRef.current = e.target.value
                      openAIManager.updateApiKey(e.target.value, customFetch);
                    }} placeholder="API_KEY" />
                  </Form.Item>
                  <Link href="https://test.staihex.com/api_key" target='_blank' style={{ float: 'right' }}>è·å–API_KEY</Link>
                </Form>
                
                
              </div>
            </Affix>
          </Col>
          <Col sm={18} md={20} style={{ flex: 1, backgroundColor: '#f0f2f5', padding: '24px 24px 0px 24px' }}>
            <div className={styles.chat}>
              {/* ğŸŒŸ æ¶ˆæ¯åˆ—è¡¨ */}
              <Bubble.List
                items={items.length > 0 ? items : [{
                  content: <WelcomeCard title="æ‚¨å¥½ï¼Œæˆ‘æ˜¯è¯­éŸ³è¯†åˆ«æ™ºèƒ½æœºå™¨äººï¼"
                    description="è¯·æŠŠéœ€è¦å¤„ç†çš„éŸ³é¢‘æ–‡ä»¶å‘é€ç»™æˆ‘å§ï¼" />, variant: 'borderless'
                }]}
                roles={roles}
                className={styles.messages}
              />
              {/* ğŸŒŸ è¾“å…¥æ¡† */}
              <div ref={messagesEndRef} style={{ backgroundColor: '#f0f2f5', width: '100%', textAlign: 'center', position: 'sticky', bottom: 2 }}>
                <Attachments
                  {...sharedAttachmentProps}
                  maxCount={1}
                  accept='audio/*'
                  placeholder={getPlaceholderFn(
                    <Result
                      title="ç‚¹å‡»æˆ–æ‹–æ‹½æ–‡ä»¶ä¸Šä¼ "
                      subTitle='æ”¯æŒçš„æ ¼å¼: wav, mp3, ogg'
                      icon={<CloudUploadOutlined />}
                      extra={
                        <Button type="primary"
                          icon={<AudioOutlined />}
                          onClick={(e) => {
                            e.stopPropagation()
                            startRecording()
                          }}
                          onMouseUp={stopRecording}
                          onMouseLeave={stopRecording}
                          disabled={isRecording}>{isRecording ? 'æ¾å¼€åœæ­¢å½•éŸ³' : 'æŒ‰ä½å¼€å§‹å½•éŸ³'}</Button>
                      }
                      style={{ padding: 0 }}
                    />,
                  )}
                />
                <div style={{ width: '100%', display: 'flex', marginTop: '4px', justifyContent: 'end' }}>
                  {agent.isRequesting() ? (
                    <Button type="primary" icon={<PoweroffOutlined />} loading disabled />
                  ) : (<Button type="primary" onClick={() => onSubmit(' ')} icon={<SendOutlined />} shape='default' disabled={fileItems.length == 0}>å‘é€</Button>)}
                </div>
                <Text style={{ marginBottom: '24px', display: 'block' }}>å†…å®¹ç”± AI å¤§æ¨¡å‹ç”Ÿæˆï¼Œè¯·ä»”ç»†ç”„åˆ«</Text>
              </div>
            </div>
          </Col>
        </Row>
      </Layout>
    </>
  );
};

export default SpeechToText;