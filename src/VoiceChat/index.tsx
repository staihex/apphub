/* eslint-disable @typescript-eslint/no-explicit-any */
import markdownit from 'markdown-it';
import { createStyles } from 'antd-style';
import React, { useEffect, useRef } from 'react';
import HeaderMenu from '../components/Header/HeaderMenu';
import { Bubble, useXAgent, useXChat } from '@ant-design/x';
import { Affix, Avatar, Button, Cascader, Col, Divider, Form, GetProp, Input, Layout, message, Row, Select, Typography } from 'antd';
import { AudioOutlined, UserOutlined } from '@ant-design/icons';
import { API_KEY } from '../config/config';
import WelcomeCard from '../components/Other/WelcomeCard';
import WaveformPlayer from '../components/Voice/WaveformPlayer';
import application13 from '../../public/images/application13.png'
import OpenAIClientManager from '../utils/OpenAIClientManager';
import { addWavHeader, concatUint8Arrays, decodeAndPlayAudio } from '../utils/utils';
import { request } from '../services/request';
import Link from 'antd/es/typography/Link';
import { useFetch } from '../contexts/useFetch';
import '../styles.css'

const { Text } = Typography;

const useStyle = createStyles(({ token, css }) => {
  return {
    chat: css`
        height: 100%;
        width: 100%;
        max-width: 700px;
        margin: 0 auto;
        box-sizing: border-box;
        display: flex;
        flex-direction: column;
        flex: 1;
        padding: 24px 24px 0px 24px;
        gap: 16px;
      `,
    messages: css`
        flex: 1;
      `,
    sender: css`
        box-shadow: ${token.boxShadow};
      `,
  };
});



const VoiceChat: React.FC = () => {
  const { styles } = useStyle();
  const { data } = useFetch();
  const currentModelrRef = React.useRef('llava:7b');
  const currentTTSRef = React.useRef('cosyvoice-2');
  const currentSTTRef = React.useRef('whisper-3');

  const messagesEndRef = useRef<HTMLDivElement>(null);
  const [messageApi, contextHolder] = message.useMessage();
  const currentApiKeyrRef = React.useRef(API_KEY);
  const [apiKey, setApiKey] = React.useState<string>(API_KEY);
  const md = markdownit({ html: true, breaks: true });

  const fileItemsRef = React.useRef<any>(null);
  const aiFileItemsRef = React.useRef<any>(null);

  const [isRecording, setIsRecording] = React.useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  const userFileStorageRef = useRef<Map<any, File>>(new Map());
  const aiFileStorageRef = useRef<Map<any, File>>(new Map());
  const isStart = React.useRef(true);
  const currentVoiceRef = React.useRef<any>('');
  const [, setVoice] = React.useState<any>('');
  //  const [audioUrl, setAudioUrl] = React.useState<string>('')
  const [sysVoice, setSysVoice] = React.useState<any>([]);

  const [forceUpdate, setForceUpdate] = React.useState(false);
  const [form] = Form.useForm();

  const [userVoice, setUserVoice] = React.useState<any>([])
  
  const [keyStatus, setKeyStatus] = React.useState<number>(0);

  const getUserVoice = async () => {
    const url = 'https://test.staihex.com/api/ai/v1/voice/list';
    const options = {
      method: 'POST', // æ˜ç¡®æŒ‡å®šè¯·æ±‚æ–¹æ³•
      headers: {
        authorization: currentApiKeyrRef.current,
      },
      data: {
        page_size: 50,
      },
    };

    request<any>(url, options)
      .then(async (response) => {
        if (response.status === 401 && currentApiKeyrRef.current !== '') {
          messageApi.open({
            type: 'error',
            content: 'API_KEYæœ‰è¯¯',
          });
          form.setFieldValue('key', '');
          setKeyStatus(1)
          setUserVoice([])
          currentApiKeyrRef.current = '';
        } else {
          const data = await response.json();
          if (data.voices) {
            setUserVoice(data.voices);
            setKeyStatus(2);
          }
        }
      })
      .catch((error) => {
        setUserVoice([])
        setKeyStatus(1)
        console.error('POST è¯·æ±‚å¤±è´¥:', error);
      });
  }

  useEffect(() => {
    getUserVoice();
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [apiKey])

  useEffect(() => {
    const url = 'https://test.staihex.com/api/ai/v1/sys_voice/list';
    const options = {
      method: 'POST', // æ˜ç¡®æŒ‡å®šè¯·æ±‚æ–¹æ³•
      data: {
        page_size: 50,
      },
    };

    request<any>(url, options)
      .then(async (response) => {
        const data = await response.json();
        console.log('POST è¯·æ±‚æˆåŠŸ:', data);
        setSysVoice(data.sys_voices);
      })
      .catch((error) => {
        console.error('POST è¯·æ±‚å¤±è´¥:', error);
      });
  }, [])


  const customFetch1 = async (url: string | URL | Request, options: any) => {

    const controller = new AbortController();
    const signal = controller.signal;

    // åˆ›å»ºæ–°çš„è¯·æ±‚é€‰é¡¹å¯¹è±¡
    const newOptions = {
      ...options,
      // headers,
      signal, // æ·»åŠ  signal ä»¥æ”¯æŒå–æ¶ˆ
    };

    try {
      // ä½¿ç”¨è‡ªå®šä¹‰çš„è¯·æ±‚é€‰é¡¹å‘é€è¯·æ±‚
      const response = await fetch(url, newOptions);
      if (!response.ok) {
        // å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯ 2xxï¼ŒæŠ›å‡ºé”™è¯¯
        const errorData = await response.json();
        if (isStart.current) {
          isStart.current = false;
          messageApi.open({
            type: 'error',
            content: errorData.error.message,
          });
          throw new Error(`HTTP error! status: ${response.status}`);
        }
      }
      return response;
    } catch (error) {
      // å¤„ç†è¯·æ±‚é”™è¯¯
      console.error('Request failed:', error);
      throw error;
    }
  };

  const customFetch = async (url: any, options: any) => {
    const controller = new AbortController();
    const signal = controller.signal;

    // åˆ›å»ºæ–°çš„è¯·æ±‚é€‰é¡¹å¯¹è±¡
    const newOptions = {
      ...options,
      signal
    };

    // const replacedString = url.replace('https://test.staihex.com', '/api');

    try {
      // ä½¿ç”¨è‡ªå®šä¹‰çš„è¯·æ±‚é€‰é¡¹å‘é€è¯·æ±‚
      const response = await fetch(url, newOptions);
      if (!response.ok) {
        // å¦‚æœå“åº”çŠ¶æ€ç ä¸æ˜¯ 2xxï¼ŒæŠ›å‡ºé”™è¯¯
        const errorData = await response.json();
        if (isStart.current) {
          isStart.current = false;
          messageApi.open({
            type: 'error',
            content: errorData.error.message,
          });
          throw new Error(`HTTP error! status: ${response.status}`);
        }
      }
      return response;
    } catch (error) {
      // å¤„ç†è¯·æ±‚é”™è¯¯
      console.error('Request failed:', error);
      throw error;
    }
  };

  const TTShandle = async (
    tgenContent: string, // å½“å‰æ®µçš„æ–‡æœ¬å†…å®¹
    context: AudioContext, // å…±äº«çš„ AudioContext
    currentTime: number // å½“å‰éŸ³é¢‘æ’­æ”¾çš„æ—¶é—´ç‚¹
  ): Promise<{ chunks: Uint8Array; currentTime: number }> => {
    let accumulatedData = new Uint8Array(0); // ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®
    const sampleRate = 22050; // é‡‡æ ·ç‡
    const numChannels = 1; // å£°é“æ•°
    const bytesPerSample = 2; // æ¯ä¸ªæ ·æœ¬çš„å­—èŠ‚æ•°
    let chunks = new Uint8Array(0); // æ‰€æœ‰ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®å—

    // å‘èµ· TTS è¯·æ±‚
    const response: any = await customFetch1('https://test.staihex.com/api/ai/v1/audio/stream_speech', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: currentApiKeyrRef.current,
      },
      body: JSON.stringify({
        model: currentTTSRef.current,
        input: tgenContent,
        voice: currentVoiceRef.current || 'yunmeng',
        speed: 1,
        response_format: 'wav',
        stream: true,
      }),
    });

    const reader = response.body.getReader();
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const buffer = new Uint8Array(value).buffer;
      const waveBytes = new Uint8Array(buffer, 8, 4);

      // å°†å­—èŠ‚è½¬æ¢ä¸ºå­—ç¬¦ä¸²

      const waveId = String.fromCharCode(...waveBytes);
      if (waveId === 'WAVE') {
        continue;
      }
      // ç´¯ç§¯æ¥æ”¶åˆ°çš„éŸ³é¢‘æ•°æ®
      accumulatedData = concatUint8Arrays(accumulatedData, value);
      chunks = concatUint8Arrays(chunks, value);

      // ç¡®ä¿æ•°æ®é•¿åº¦æ˜¯ 2 å­—èŠ‚å¯¹é½
      if (accumulatedData.length % bytesPerSample !== 0) continue;

      // å®æ—¶æ’­æ”¾å½“å‰ç´¯ç§¯çš„æ•°æ®
      currentTime = decodeAndPlayAudio(accumulatedData, sampleRate, numChannels, bytesPerSample, context, currentTime);

      // æ¸…ç©ºç´¯ç§¯æ•°æ®ï¼Œå‡†å¤‡æ¥æ”¶æ–°æ•°æ®å—
      accumulatedData = new Uint8Array(0);
    }

    // è¿”å›å½“å‰æ®µçš„éŸ³é¢‘æ•°æ®å’Œæ›´æ–°åçš„æ’­æ”¾æ—¶é—´
    return { chunks, currentTime };
  };

  const openAIManager = OpenAIClientManager.getInstance();
  openAIManager.initializeClient(currentApiKeyrRef.current, customFetch);

  const [agent] = useXAgent({
    request: async (_info, callbacks) => {
      const { onError } = callbacks;

      let attContent: string = '';
      const tgenContent: string = '';

      let fullContent = ''; // å­˜å‚¨å®Œæ•´çš„æµæ•°æ®
      let currentIndex = 0; // å½“å‰è¾“å‡ºçš„å­—ç¬¦ç´¢å¼•
      let isTyping = false; // æ˜¯å¦æ­£åœ¨æ‰“å­—
      const typingInterval = 5; // é€å­—è¾“å‡ºçš„é—´éš”æ—¶é—´(æ¯«ç§’)

      let allChunks = new Uint8Array(0); // æ‰€æœ‰ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®
      const context = new AudioContext(); // å…±äº«çš„ AudioContext
      let currentTime = context.currentTime; // å½“å‰éŸ³é¢‘æ’­æ”¾çš„æ—¶é—´ç‚¹

      try {
        // è°ƒç”¨è¯­éŸ³è½¬æ–‡å­—æ¥å£
        const att = await openAIManager.getClient().audio.transcriptions.create({
          model: currentSTTRef.current,
          file: fileItemsRef.current,
        });
        attContent += att.text || '';

        const usermessageId = Date.now().toString();
        userFileStorageRef.current.set(usermessageId, fileItemsRef.current);

        // å°†è¯­éŸ³è½¬æ–‡å­—çš„ç»“æœæ›´æ–°åˆ°ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯åˆ—è¡¨
        setMessages((prevMessages) => {
          const filteredMessages = prevMessages.filter((msg) => msg.message.trim() !== '');
          return [
            ...filteredMessages,
            {
              id: usermessageId, // ç”Ÿæˆå”¯ä¸€ ID
              message: attContent, // è¯­éŸ³è½¬æ–‡å­—çš„ç»“æœ
              status: 'local', // æ ‡è®°ä¸ºç”¨æˆ·è¾“å…¥
            },
          ];
        });
        console.log("ç”¨æˆ·è¯­éŸ³è½¬æ–‡å­—:", attContent);

        // è°ƒç”¨å¤§æ¨¡å‹æ¥å£
        const tgen = await openAIManager.getClient().chat.completions.create({
          model: currentModelrRef.current,
          messages: [
            { role: 'system', content: 'ä½ æ“…é•¿ç”¨ä¸­æ–‡å›ç­”' },
            { role: 'user', content: [{ type: 'text', text: attContent as string }] },
          ],
          stream: true,
        });
        const aimessageId = Date.now().toString();

        // å®šæ—¶å™¨å‡½æ•°ï¼šé€å­—è¾“å‡º
        const typeNextChar = () => {
          if (currentIndex < fullContent.length) {
            if (currentIndex === 0) {
              setMessages((prevMessages) => [
                ...prevMessages,
                {
                  id: aimessageId, // ç”Ÿæˆå”¯ä¸€ ID
                  message: tgenContent, // AI å›å¤çš„å†…å®¹
                  status: 'loading', // æ ‡è®°ä¸º AI è¾“å…¥
                },
              ]);
            } else {
              setMessages((prevMessages) =>
                prevMessages.map((msg) =>
                  msg.id === aimessageId
                    ? { ...msg, message: fullContent.slice(0, currentIndex + 1) } // æ›´æ–°åŒ¹é…çš„æ¶ˆæ¯
                    : msg // å…¶ä»–æ¶ˆæ¯ä¿æŒä¸å˜
                )
              );
            }
            currentIndex++;
            setTimeout(typeNextChar, typingInterval); // ç»§ç»­ä¸‹ä¸€æ¬¡
          } else {
            isTyping = false; // æ‰“å­—ç»“æŸ
          }
        };

        // ç”¨äºç´¯ç§¯å½“å‰å¥å­çš„å†…å®¹
        let sentenceBuffer = '';

        // å¼‚æ­¥å¤„ç† TTS çš„ä»»åŠ¡é˜Ÿåˆ—
        const ttsQueue: string[] = [];

        for await (const chunk of tgen) {
          const tempStr = chunk.choices[0]?.delta?.content || '';
          fullContent += tempStr;

          // æ‰“å­—æœºæ•ˆæœ
          if (!isTyping) {
            isTyping = true;
            typeNextChar();
          }

          // å°†æ–°å†…å®¹æ·»åŠ åˆ°å¥å­ç¼“å†²åŒº
          sentenceBuffer += tempStr;

          // æ£€æŸ¥å¥å­ç¼“å†²åŒºæ˜¯å¦åŒ…å«å®Œæ•´çš„å¥å­
          const sentenceEndIndex = sentenceBuffer.match(/[ã€‚ï¼ï¼Ÿ]/)?.index;
          if (sentenceEndIndex !== undefined) {
            // æå–å®Œæ•´çš„å¥å­
            const sentence = sentenceBuffer.slice(0, sentenceEndIndex + 1);
            sentenceBuffer = sentenceBuffer.slice(sentenceEndIndex + 1); // ç§»é™¤å·²å¤„ç†çš„å¥å­

            // å¦‚æœæœ‰æœ‰æ•ˆæ–‡æœ¬å†…å®¹ï¼ŒåŠ å…¥é˜Ÿåˆ—
            if (sentence.trim() !== '') {
              ttsQueue.push(sentence);
            }
          }
        }

        // å¤„ç†å‰©ä½™çš„å¥å­ç¼“å†²åŒºå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if (sentenceBuffer.trim() !== '') {
          ttsQueue.push(sentenceBuffer);
        }

        // é¡ºåºæ‰§è¡Œ TTS ä»»åŠ¡
        for (const sentence of ttsQueue) {
          const { chunks, currentTime: updatedTime } = await TTShandle(sentence, context, currentTime);
          allChunks = concatUint8Arrays(allChunks, chunks); // ç´¯ç§¯æ‰€æœ‰éŸ³é¢‘æ•°æ®
          currentTime = updatedTime; // æ›´æ–°å½“å‰æ’­æ”¾æ—¶é—´
        }

        // æ‰€æœ‰è¯­éŸ³æ’­æ”¾å®Œæˆåï¼Œç”Ÿæˆå®Œæ•´çš„ WAV æ–‡ä»¶
        const wavAudioData = addWavHeader(allChunks, 22050, 1, 16); // 16 æ˜¯æ¯ä¸ªæ ·æœ¬çš„ä½æ•°
        const blob = new Blob([wavAudioData], { type: 'audio/wav' });
        const file = new File([blob], `recorded_${Date.now()}.wav`, { type: 'audio/wav' });

        // ä¿å­˜æ–‡ä»¶
        aiFileItemsRef.current = file;
        aiFileStorageRef.current.set(aimessageId, file);
        setForceUpdate((prev) => !prev);
        console.log("è¯¢é—®å¤§æ¨¡å‹ç»“æœ:", tgenContent);

      } catch (error: any) {
        // handle error
        onError(error);
      }
    },
  });

  const { onRequest, messages, setMessages } = useXChat({
    agent,
  });

  useEffect(() => {
    // å½“æ¶ˆæ¯åˆ—è¡¨æ›´æ–°æ—¶ï¼Œæ»šåŠ¨åˆ°æœ€åº•éƒ¨
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  const items: GetProp<typeof Bubble.List, 'items'> = messages.map(({ id, message, status }) => ({
    key: id,
    avatar: { src: status == 'local' ? <Avatar style={{ backgroundColor: '#2467FF' }} icon={<UserOutlined />} /> : <Avatar src={application13} /> },
    role: status === 'local' ? 'local' : 'ai',
    styles: {
      content: {
        borderRadius: 16,
        display: 'flex',
        justifyContent: 'flex-end',
        backgroundColor: status === 'local' ? 'rgb(239, 246, 255)' : '#FFF',
      },
    },
    messageRender: () => {
      if (status === 'local' && message !== '') {
        return <div style={{ display: 'flex', flexDirection: 'column' }} >
          {userFileStorageRef.current.has(id) && <WaveformPlayer autoPlay={false} file={userFileStorageRef.current.get(id)} />}

          <Divider />
          <Typography>
            <div dangerouslySetInnerHTML={{ __html: md.render(message) }} />
          </Typography>
        </div>
      } else {
        return <div style={{ display: 'flex', flexDirection: 'column' }} >
          {aiFileStorageRef.current.has(id) && <WaveformPlayer key={forceUpdate ? 'update' : 'no-update'} autoPlay={false} file={aiFileStorageRef.current.get(id)} />}
          <Divider />
          <Typography>
            <div dangerouslySetInnerHTML={{ __html: md.render(message) }} />
          </Typography>
        </div>
      }

    },
  }));

  const roles: GetProp<typeof Bubble.List, 'roles'> = {
    ai: {
      placement: 'start',
      typing: { step: 5, interval: 20 },
      styles: {
        content: {
          borderRadius: 16,
        },
      },
    },
    local: {
      placement: 'end',
      variant: 'shadow',
    },
  };

  const onSubmit = (nextContent: string) => {
    // if (!nextContent) return;
    onRequest(nextContent);
    isStart.current = true;
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = () => {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices
        .getUserMedia({ audio: true })
        .then((stream) => {
          const mediaRecorder = new MediaRecorder(stream);
          mediaRecorderRef.current = mediaRecorder;
          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunksRef.current.push(event.data);
            }
          };
          mediaRecorder.start();
          setIsRecording(true);
        })
        .catch((error) => {
          console.error('å½•éŸ³å¤±è´¥:', error);
          message.error('å½•éŸ³å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
        });
    } else {
      message.error('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
    }
  };

  // åœæ­¢å½•éŸ³å¹¶ä¸Šä¼ 
  const stopRecording = () => {
    const mediaRecorder = mediaRecorderRef.current;
    if (mediaRecorder) {
      mediaRecorder.stop();
      setIsRecording(false);
      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        audioElementRef.current = new Audio(audioUrl);
        // audioElementRef.current.play();

        // å°†å½•éŸ³æ–‡ä»¶ä¸Šä¼ 
        const file = new File([audioBlob], `recorded_${Date.now()}.wav`, { type: 'audio/wav' });

        fileItemsRef.current = file
        onSubmit('')
        audioChunksRef.current = []; // æ¸…ç©ºéŸ³é¢‘æ•°æ®
      };
    }
  };

  return (
    <>
      {contextHolder}
      <Layout style={{ minHeight: '100vh', display: 'flex', flexDirection: 'column' }}>
        {/* HeaderMenu */}
        <Affix offsetTop={0}>
          <Layout.Header style={{ background: 'transparent', width: '100%', padding: 0 }}>
            <HeaderMenu name='è¯­éŸ³äº¤äº’' />
          </Layout.Header>
        </Affix>

        {/* å†…å®¹åŒºåŸŸ */}
        <Row style={{ flex: 1 }}>
          <Col sm={6} md={4} style={{ backgroundColor: '#FFF', padding: '24px 24px 0px 24px' }}>
            <Affix offsetTop={90}>
              <div>
                <Form layout="vertical" form={form}>
                  <Form.Item initialValue="whisper-3" label="è¯­éŸ³è¯†åˆ«æ¨¡å‹" name='STT' rules={[{ required: true, message: 'è¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹' }]}>
                    <Select
                      style={{ width: '100%' }}
                      onChange={(value) => {
                        currentSTTRef.current = value;
                      }}
                      options={data?.audio2text}
                    />
                  </Form.Item>
                  <Form.Item initialValue="llava:7b" label="å¤§è¯­è¨€æ¨¡å‹" name='model' rules={[{ required: true, message: 'è¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹' }]}>
                    <Select
                      style={{ width: '100%' }}
                      onChange={(value) => {
                        currentModelrRef.current = value;
                      }}
                      options={data?.llm}
                    />
                  </Form.Item>
                  <Form.Item initialValue={"cosyvoice-2"} name='TTS' label="è¯­éŸ³åˆæˆæ¨¡å‹" rules={[{ required: true, message: 'è¯·é€‰æ‹©è¯­éŸ³åˆæˆæ¨¡å‹' }]}>
                    <Select
                      onChange={(value) => {
                        currentTTSRef.current = value
                      }}
                      options={data?.text2audio}
                    />
                  </Form.Item>
                  <Form.Item style={{marginBottom:'8px'}}>
                    <Form.Item style={{marginBottom: '8px'}} initialValue={API_KEY} label="API_KEY" name='apikey' rules={[{ required: true, message: 'è¯·è¾“å…¥API_KEY' }]}>
                      <Input onChange={(e) => {
                        // æ›´æ–°API_KEY
                        setApiKey(e.target.value);
                        currentApiKeyrRef.current = e.target.value
                        openAIManager.updateApiKey(e.target.value, customFetch);
                      }} placeholder="API_KEY" />
                    </Form.Item>
                    <Link href="https://test.staihex.com/api_key" target='_blank' style={{ float: 'right' }}>è·å–API_KEY</Link>
                  </Form.Item>
                  <Form.Item extra={keyStatus === 0 ? 'è¯·å…ˆé…ç½®API_KEY' : keyStatus === 1 ? 'API_KEYæœ‰è¯¯' : ''} initialValue={[1,"yunmeng"]} name='voice' label="éŸ³è‰²é€‰æ‹©" rules={[{ required: true, message: 'è¯·é€‰æ‹©éŸ³è‰²!' }]}>
                    <Cascader
                        onClick={() => {
                          getUserVoice()
                        }}
                        placeholder={keyStatus === 0 ? 'è¯·å…ˆé…ç½®API_KEY' : keyStatus === 1 ? 'API_KEYæœ‰è¯¯' : 'è¯·é€‰æ‹©éŸ³è‰²'}
                        disabled={keyStatus !== 2}
                        options={[
                          {
                            value: 1,
                            label: 'ç³»ç»ŸéŸ³è‰²',
                            children: sysVoice.map((d: { name: any; desc: any; }) => ({
                              value: d.name,
                              label: d.desc,
                            }))
                          },
                          {
                            value: 2,
                            label: 'ç”¨æˆ·éŸ³è‰²',
                            disabled: userVoice?.length === 0,
                            children: userVoice?.map((d: { name: any; desc: any; }) => ({
                              value: d.name,
                              label: d.name,
                            }))
                          }
                        ]}
                        onChange={(value) => {
                          if (value.length < 2) return;
                          currentVoiceRef.current = value[1]
                          setVoice(value[1]);
                          form.setFieldsValue({ voice: value });
                        }}
                      />
                  </Form.Item>
                </Form>
                {/* <Text style={{ display: 'block', marginTop: '32px' }}>é€‰æ‹©éŸ³è‰²</Text> */}

              </div>
            </Affix>
          </Col>
          <Col sm={18} md={20} style={{ flex: 1, backgroundColor: '#f0f2f5', padding: '24px 24px 0px 24px' }}>
            <div className={styles.chat}>
              {/* ğŸŒŸ æ¶ˆæ¯åˆ—è¡¨ */}
              <Bubble.List
                items={items.length > 0 ? items : [{
                  content: <WelcomeCard title="æ‚¨å¥½ï¼Œæˆ‘æ˜¯è¯­éŸ³äº¤äº’æ™ºèƒ½æœºå™¨äººï¼"
                    description="è¯·å°½æƒ…å‘æˆ‘æé—®å§ï¼" />, variant: 'borderless'
                }]}
                roles={roles}
                className={styles.messages}
              />
              {/* ğŸŒŸ è¾“å…¥æ¡† */}
              <div ref={messagesEndRef} style={{ backgroundColor: '#f0f2f5', width: '100%', zIndex: 99, textAlign: 'center', position: 'sticky', bottom: 2 }}>
                <Button
                  type="primary"
                  block
                  icon={<AudioOutlined />}
                  onClick={(e) => {
                    e.stopPropagation()
                    startRecording()
                  }}
                  onMouseUp={stopRecording}
                  onMouseLeave={stopRecording}
                  disabled={isRecording || apiKey.trim() === ''}
                >
                  {isRecording ? 'æ¾å¼€åœæ­¢å½•éŸ³' : 'æŒ‰ä½å¼€å§‹å½•éŸ³'}
                </Button>

                <Text style={{ marginBottom: '24px', display: 'block' }}>å†…å®¹ç”± AI å¤§æ¨¡å‹ç”Ÿæˆï¼Œè¯·ä»”ç»†ç”„åˆ«</Text>
              </div>
            </div>
          </Col>
        </Row>
      </Layout>
    </>
  );
};

export default VoiceChat;